# Dynamic-Path-Prediction-in-IoT-Systems

# Design Reinforcement Environment-Code_Training_Agent
This code allow us to design our Reinforcement Learning, using a DQN algorithm and an epsilon greedy policy.

# Energy_Consumption_Statistical-Analysis-1
This code allow us to compare our algorithm to two algorithms Dijkstra and A* by plotting the cumulative energy consumption, computing the average degree, diameter average link of three network topology(20, 25, 30 nodes) and also computing the standard deviation, the mean and the CVP(Pearson Variation Coefficient) for these 3 network topology. We also make a comparison on the alive number of nodes in function of the request.

# Network_Lifetime_Statistical-Analysis-2
This code allow us to have the Network Lifetime using RLDPP( our algorithm) and make a comparison with Dijkstra and A* algorithm using 20, 25, 30 nodes.


